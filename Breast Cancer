#!/usr/bin/env python
# coding: utf-8

# In[48]:


import numpy as np 
import pandas as pd 
import matplotlib.pyplot as plt
import seaborn as sns








dft= pd.read_csv(r"C:\Users\Vansh\Downloads\data (1).csv",encoding=('ISO-8859-1'),low_memory =False)


# In[50]:


dft.head(1)


# In[51]:


dft.shape


# # Checking Null Values
# 

# In[52]:


print("\nNull Values:\n", dft.isnull().sum())


# # Checking Missing Values
# 

# In[53]:


print("\nMissing Values:\n", dft.isna().sum())


# # Information of data
# 

# In[54]:


dft.info()


# # Statistical Description of Data
# 

# In[55]:


dft.describe()


# # Extracting Mean, Squared Error and Worst Features with Diagnosis
# 

# In[56]:


dft_mean = dft[dft.columns[:11]]
dft_se = dft.drop(dft.columns[1:11], axis=1);
dft_se = dft_se.drop(dft_se.columns[11:], axis=1)
dft_worst = dft.drop(dft.columns[1:21], axis=1)


# Count Based On Diagnosis
# 

# In[57]:


dft.diagnosis.value_counts()


# In[58]:


dft.diagnosis.value_counts() \
    .plot(kind="bar", width=0.1, color=["lightgreen", "cornflowerblue"], legend=1, figsize=(8, 5))
plt.xlabel("(0 =  Benign) (1 =Malignant)", fontsize=12)
plt.ylabel("Count", fontsize=12)
plt.xticks(fontsize=12);
plt.yticks(fontsize=12)
plt.legend([" Benign"], fontsize=12)
plt.show()


# Correlation with diagnosis:

# In[59]:


def corrwithdia(dftx):
    import matplotlib.pyplot as plt
    name = str([x for x in globals() if globals()[x] is dftx][0])
    if name == 'dft':
        x = "All"
    elif name == 'dft_mean':
        x = "Mean"
    elif name == 'dft_se':
        x = "Squared Error"
    elif name == 'dft_worst':
        x = "Worst"
    plt.figure(figsize=(20, 8))
    dftx.drop('diagnosis', axis=1).corrwith(dftx.diagnosis).plot(kind='bar', grid=True, title="Correlation of {} Features with Diagnosis".format(x), color="cornflowerblue");


# correlation of Mean Features with Diagnosis
# 

# In[60]:


corrwithdia(dft_mean)


# Correlation of Squared Error Features with Diagnosis
# 

# In[61]:


corrwithdia(dft_se)


# Correlation of Worst Features with Diagnosis
# 

# In[62]:


corrwithdia(dft_worst)


# Extracting Mean, Squared Error and Worst Features

# In[63]:


dft_mean_cols = list(dft.columns[1:11])
dft_se_cols = list(dft.columns[11:21])
dft_worst_cols = list(dft.columns[21:])


# Split into two Parts Based on Diagnosis

# In[64]:


dftM = dft[dft['diagnosis'] == 1]
dftB = dft[dft['diagnosis'] == 0]


# Nucleus Mean Features vs Diagnosis

# In[65]:


plt.rcParams.update({'font.size': 8})
fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(8, 10))
axes = axes.ravel()
for idx, ax in enumerate(axes):
    ax.figure
    binwidth = (max(dft[dft_mean_cols[idx]]) - min(dft[dft_mean_cols[idx]])) / 50
    ax.hist([dftM[dft_mean_cols[idx]], dftB[dft_mean_cols[idx]]],
            bins=np.arange(min(dft[dft_mean_cols[idx]]), max(dft[dft_mean_cols[idx]]) + binwidth, binwidth), alpha=0.5,
            stacked=True, label=['M', 'B'], color=['b', 'g'])
    ax.legend(loc='upper right')
    ax.set_title(dft_mean_cols[idx])
plt.tight_layout()
plt.show()


# Nucleus Worst Features vs Diagnosis

# In[67]:


plt.rcParams.update({'font.size': 8})
fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(8, 10))
axes = axes.ravel()
for idx, ax in enumerate(axes):
    ax.figure
    binwidth = (max(dft[dft_worst_cols[idx]]) - min(dft[dft_worst_cols[idx]])) / 50
    ax.hist([dftM[dft_worst_cols[idx]], dftB[dft_worst_cols[idx]]],
            bins=np.arange(min(dft[dft_worst_cols[idx]]), max(dft[dft_worst_cols[idx]]) + binwidth, binwidth), alpha=0.5,
            stacked=True, label=['M', 'B'], color=['b', 'g'])
    ax.legend(loc='upper right')
    ax.set_title(dft_worst_cols[idx])
plt.tight_layout()
plt.show()


# Checking Multicollinearity Between Different Features

# In[68]:


def pairplot(dftx):
    import seaborn as sns
    name = str([x for x in globals() if globals()[x] is dftx][0])
    if name == 'dft_mean':
        x = "Mean"
    elif name == 'dft_se':
        x = "Squared Error"
    elif name == 'dft_worst':
        x = "Worst"
    sns.pairplot(data=dftx, hue='diagnosis', palette='crest', corner=True).fig.suptitle('Pairplot for {} Featrues'.format(x), fontsize = 20)


# # Mean Features:
# 
# 

# Squared Error Features:
# 
# 

# In[70]:


pairplot(dft_se)


# Worst features:
# 
# 

# In[71]:


pairplot(dft_worst)


# # Correlation Heartmap between Nucleus Feature

# In[72]:


corr_matrix = dft.corr()  

mask = np.zeros_like(corr_matrix, dtype=np.bool_)
mask[np.triu_indices_from(corr_matrix)] = True

fig, ax = plt.subplots(figsize=(22, 10))
ax = sns.heatmap(corr_matrix, mask=mask, annot=True, linewidths=0.5, fmt=".2f", cmap="YlGn");
bottom, top = ax.get_ylim()
ax.set_ylim(bottom + 0.5, top - 0.5);
ax.set_title("Correlation Matrix Heatmap including all features");


# Outliers

# In[73]:


for column in dft:
    plt.figure()
    dft.boxplot([column])
    plt.show()


# Outlier removal

# In[74]:


from numpy import percentile
for column in dft.columns:
    q25, q75 = percentile(dft[column], 25), percentile(dft[column], 75)
    iqr = q75 - q25
    print('Percentiles: 25th=%.3f, 75th=%.3f, IQR=%.3f' % (q25, q75, iqr))
    cut_off = iqr * 1.5
    lower, upper = q25 - cut_off, q75 + cut_off
    outliers = [x for x in dft[column] if x < lower or x > upper]
    print('Identified outliers: %d' % len(outliers))
    outliers_removed = [x for x in dft[column] if x >= lower and x <= upper]
    print('Non-outlier observations: %d' % len(outliers_removed))
    dft = dft[dft[column] < upper]
    plt.figure()
    dft.boxplot([column])
    plt.show()


# In[ ]:




